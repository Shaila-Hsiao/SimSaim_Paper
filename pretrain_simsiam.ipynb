{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "## Import SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ccb55986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from lightly.transforms import SimSiamTransform\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df03c7",
   "metadata": {},
   "source": [
    "## parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad18b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練參數\n",
    "parameters = {\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"epochs\": 200,\n",
    "    \"batch_size\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"simsaim_tiny_imagenet\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.6,\n",
    "    \"architecture\": \"SimSaim\",\n",
    "    \"dataset\": \"tiny_imagenet\",\n",
    "    \"epochs\": 200,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfee0f",
   "metadata": {},
   "source": [
    "## 建立 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "707fc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SimSiamProjectionHead(512, 512, 128)\n",
    "        self.prediction_head = SimSiamPredictionHead(128, 64, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(f)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "resnet = torchvision.models.resnet18()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = SimSiam(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b14cedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimSiam(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (projection_head): SimSiamProjectionHead(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=512, out_features=128, bias=False)\n",
       "      (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): SimSiamPredictionHead(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=64, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定設備\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9be3f2",
   "metadata": {},
   "source": [
    "## 資料處理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b042a",
   "metadata": {},
   "source": [
    "### 照片增強處理與載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd0838ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from lightly.transforms import SimSiamTransform\n",
    "\n",
    "# 更新 SimSiamTransform，加入 Grayscale 轉換\n",
    "# Tiny Imagenet 大小為64\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # 將灰度圖轉為 3 通道\n",
    "    SimSiamTransform(input_size=64)\n",
    "])\n",
    "\n",
    "ds = load_dataset(\"zh-plus/tiny-imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981f08f",
   "metadata": {},
   "source": [
    "### 自行定義DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d91b7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定義 Dataset 類，應用 transform\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.dataset[idx][\"image\"]\n",
    "        img0, img1 = self.transform(img), self.transform(img)\n",
    "        return img0, img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "508bf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TinyImageNetDataset(ds[\"train\"], transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca971bc3",
   "metadata": {},
   "source": [
    "### 設定 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37621a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 DataLoader\n",
    "dataloader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=parameters[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True  # 禁用 pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0668c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義損失函數和優化器\n",
    "criterion = NegativeCosineSimilarity()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=parameters[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2deadc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 1802/3125 [06:59<04:33,  4.84batch/s, loss=-0.74] "
     ]
    }
   ],
   "source": [
    "# 開始訓練\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(parameters[\"epochs\"]):\n",
    "    total_loss = 0\n",
    "    # 使用 tqdm 包裝 dataloader，顯示 batch 進度\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "        for batch in tepoch:\n",
    "            x0, x1 = batch[0]\n",
    "            x0 = x0.to(device)\n",
    "            x1 = x1.to(device)\n",
    "            \n",
    "            # 更新解包為兩個輸出\n",
    "            z0, p0 = model(x0)\n",
    "            z1, p1 = model(x1)\n",
    "            \n",
    "            loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "            total_loss += loss.detach()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 在進度條中顯示損失值\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    # log metrics to wandb\n",
    "    wandb.log({ \"Loss\": avg_loss})\n",
    "    print(f\"Epoch: {epoch+1:>02}, Average Loss: {avg_loss:.5f}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07d543",
   "metadata": {},
   "source": [
    "## 儲存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f576e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./pretrainModel/simsaim/pretrained_simsiam.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c7a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
